{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f277b64-cf72-467b-9881-50f5f0527980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f7fd8e0-1581-4e1f-8855-99ec736c7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id', 'text', 'label', 'intensity']\n",
    "path = \"./\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40e195a1-4a91-4c8d-8bb7-7eccdad30e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_train = pd.read_csv(path + 'angertraindata.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "fear_train = pd.read_csv(path + 'feartraindata.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "joy_train = pd.read_csv(path + 'joytraindata.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "sad_train = pd.read_csv(path + 'sadtraindata.txt', header=None, sep='\\t', names=cols, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad128ab3-c3b9-4481-be0f-27d8780317b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(anger_train['text'])\n",
    "\n",
    "X_anger_train = tokenizer.texts_to_sequences(anger_train['text'])\n",
    "X_fear_train = tokenizer.texts_to_sequences(fear_train['text'])\n",
    "X_joy_train = tokenizer.texts_to_sequences(joy_train['text'])\n",
    "X_sad_train = tokenizer.texts_to_sequences(sad_train['text'])\n",
    "\n",
    "max_len = max([len(seq) for seq in X_anger_train + X_fear_train + X_joy_train + X_sad_train])\n",
    "X_anger_train = pad_sequences(X_anger_train, maxlen=max_len, padding='post')\n",
    "X_fear_train = pad_sequences(X_fear_train, maxlen=max_len, padding='post')\n",
    "X_joy_train = pad_sequences(X_joy_train, maxlen=max_len, padding='post')\n",
    "X_sad_train = pad_sequences(X_sad_train, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e96cef67-3927-46c9-9aa8-7394c9db9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c898cb46-53c8-4316-afcd-77c9b264fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.1192 - val_loss: 0.1347\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0214 - val_loss: 0.1139\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0229 - val_loss: 0.0957\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0211 - val_loss: 0.1036\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0215 - val_loss: 0.0985\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0191 - val_loss: 0.0878\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0205 - val_loss: 0.0935\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0192 - val_loss: 0.1143\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0177 - val_loss: 0.0873\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0132 - val_loss: 0.0637\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0303 - val_loss: 0.1162\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0246 - val_loss: 0.1108\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0230 - val_loss: 0.1026\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0212 - val_loss: 0.1075\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0181 - val_loss: 0.1243\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0167 - val_loss: 0.1396\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0152 - val_loss: 0.1237\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0128 - val_loss: 0.1034\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0129 - val_loss: 0.0980\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0128 - val_loss: 0.1059\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0322 - val_loss: 0.1515\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0280 - val_loss: 0.1440\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0267 - val_loss: 0.1683\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0214 - val_loss: 0.1377\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0185 - val_loss: 0.1385\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0164 - val_loss: 0.1322\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0132 - val_loss: 0.1286\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0136 - val_loss: 0.1294\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0112 - val_loss: 0.1242\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0102 - val_loss: 0.1690\n",
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0288 - val_loss: 0.1392\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0255 - val_loss: 0.0992\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0244 - val_loss: 0.1145\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0203 - val_loss: 0.1004\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0203 - val_loss: 0.0943\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0194 - val_loss: 0.1171\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0173 - val_loss: 0.1044\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0142 - val_loss: 0.1010\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0128 - val_loss: 0.0776\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0132 - val_loss: 0.0911\n"
     ]
    }
   ],
   "source": [
    "history_anger = model.fit(X_anger_train, anger_train['intensity'], epochs=10, batch_size=32, validation_split=0.2)\n",
    "history_fear = model.fit(X_fear_train, fear_train['intensity'], epochs=10, batch_size=32, validation_split=0.2)\n",
    "history_joy = model.fit(X_joy_train, joy_train['intensity'], epochs=10, batch_size=32, validation_split=0.2)\n",
    "history_sad = model.fit(X_sad_train, sad_train['intensity'], epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4555dbc-a017-49cf-ade0-b1b6ce087a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val_padded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have X_val_padded, y_val_arr, X_test_padded, and y_test_arr defined\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m val_loss_anger \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mX_val_padded\u001b[49m, y_val_arr)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Loss - Anger: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss_anger\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m val_loss_fear \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_val_padded, y_val_arr)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val_padded' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "val_loss_anger = model.evaluate(X_val_padded, y_val_arr)\n",
    "print(f\"Validation Loss - Anger: {val_loss_anger}\")\n",
    "\n",
    "val_loss_fear = model.evaluate(X_val_padded, y_val_arr)\n",
    "print(f\"Validation Loss - Fear: {val_loss_fear}\")\n",
    "\n",
    "val_loss_joy = model.evaluate(X_val_padded, y_val_arr)\n",
    "print(f\"Validation Loss - Joy: {val_loss_joy}\")\n",
    "\n",
    "val_loss_sad = model.evaluate(X_val_padded, y_val_arr)\n",
    "print(f\"Validation Loss - Sad: {val_loss_sad}\")\n",
    "\n",
    "test_loss_anger = model.evaluate(X_test_padded, y_test_arr)\n",
    "print(f\"Test Loss - Anger: {test_loss_anger}\")\n",
    "\n",
    "test_loss_fear = model.evaluate(X_test_padded, y_test_arr)\n",
    "print(f\"Test Loss - Fear: {test_loss_fear}\")\n",
    "\n",
    "test_loss_joy = model.evaluate(X_test_padded, y_test_arr)\n",
    "print(f\"Test Loss - Joy: {test_loss_joy}\")\n",
    "\n",
    "test_loss_sad = model.evaluate(X_test_padded, y_test_arr)\n",
    "print(f\"Test Loss - Sad: {test_loss_sad}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
